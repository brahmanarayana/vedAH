+++
title = "02 Language, Syntax and Recursiveness"

+++

When I use the term ‘language’, what I have in mind is languages such as English or Sanskrit, modern or classical, world languages or tribal languages. Languages change and evolve over time. They are born and they die. They belong to or originate in a specific community though they may be adopted by others and become widespread. But language is a system in which everything hangs together, *où tout se tient* as de Saussure put it.

The scientific study of language or linguistics distinguishes three domains: Phonology, Syntax and Semantics. Phonology deals with the sounds of language. It is typically concerned with such differences as Śākalya studied when he made his distinction between Saṃhitā and Padapāṭha in Chapter 4. It is dependent on structures of the mouth and the inner and outer ear, which restrict the sounds of human language and distinguish it from the chirping of birds or the mowing of cows which are also systems of sound that are used for communication but are not language.

Syntax deals with the structure of sentences. It distinguishes statements from questions or commands, actives from passives, future and past tenses, singular and plural and many other modes and categories. It may or may not be restricted by word order.

Semantics deals with meaning, that is, the world to which language refers, which it denotes or connotes, addresses, hears, sees, smells, remembers, listens to, imagines or depicts. Language does this by means of words but not only words. Semantics is closely connected with syntax because we understand not only words but also sentences. Which is primary—word meaning or sentence meaning—is a favourite topic of discussion among Indian linguists and philosophers of language. Words are, obviously, more manageable than sentences. They constitute a finite set and can be listed in a dictionary or encyclopaedia, in alphabetical or another order. Sentences are infinite in number.

How can sentences be infinite in number and how can infinite numbers of things be learned or interiorated? First, we have to know what infinity means. It means indefinitely large. An example is the set of integers: 1, 2, 3, 4, 5,…. It is infinitely large not because we arrive, at a certain moment, at an integer written with a special symbol that stands for ‘infinite’. It means: whenever ‘1’, belongs to it, the next number ‘2’ also belongs to it; and if ‘2’ belongs to it, ‘3’ does too. The set of integers is infinite because for each of its members, the next member is also a member and there is no end to that …. As it happens, ‘2’ is the same as ‘1 \+ 1,’ ‘3’ is the same as ‘2 \+ 1’, etc. We are able to express it neatly with the help of a little algebra: the set of integers has infinitely many members, because for any number *n*, it also has the next number: *n* \+ 1. That process can be repeated as often as we like and the number of natural numbers is therefore indefinitely large. There is no upper limit.

Returning to language we have seen that the number of words is finite but the number of sentences is infinitely large. This is due to a property of syntax called *recursiveness*. It means that also in language a structure may be repeated indefinitely often without there being an upper limit. An example from English is ‘*He said A*’, where ‘*A*’ is a sentence. That structure is repeated in *He said that he said A*; and once more in *He said that he said that he said A.* And so on. The reader may object that such sentences do not actually occur in English. It is true, but some English sentences cannot be analysed without presupposing that such structures underlie them, e.g., *Betty told me that Kumar, when asked about his opinion, immediately said that he had said A already.* When such sentences get longer they become increasingly unintelligible, but their underlying recursive structure remains the same. In other cases, the intelligibility or unintelligibility continues unabated, as in teacher’s lineages \(*guruparamparā*\) such as: ‘Pautimāṣya from Gaupavana, Gaupavana from Kauśika, Kauśika from Kauṇḍinya, Kauṇḍinya from Śaṇḍilya, Śaṇḍilya from Kauśika and Gautama, Gautama from Āgniveśya’ etc. in the Bṛhad-Āraṇyaka Upaniṣad.

Do we actually find very long sentences in natural languages? I am not a writer so I cannot construct a good example but the reader who is familiar with any of the following may look at Sanskrit compounds, a page of the Kādambarī, Navya-Nyāya, Proust or Thomas Mann. Take the longest compound or sentence you can find. Assume that the longest sentence you can find occurs in Proust. Call it P. I can *always* construct a longer one. Here it is: ‘Proust wrote *P*.’ This can be repeated ad libitum, and there is no upper bound.

How can things that are infinite in number be learned? By learning general principles that generate infinity. Recursiveness is one of these. It may be represented by an inverted tree. I shall start with a finite example, a simple syntactic structure that occurs in natural languages, perhaps in all languages \(an empirical matter\): the distinction between subject and predicate. It is *not* recursive.

Take the example: ‘Yājñavalkya taught Maitreyī’ or ‘Y taught M’. In English syntax, ‘Y’ is the subject and ‘taught M’ is the predicate. The predicate, therefore, consists of two parts: a verb and an object. Not all sentences in all languages have that simple structure. But a surprisingly large number can be reduced to such structures, using an astonishing proliferation of rules. So let us put those rules aside and concentrate on the basic structure of the sentence which is a *hierarchical* structure because it consists of two levels: subject and predicate, and, within predicate, verb and object:

![image](images/000044.png)

Linguists have proceeded to unearth much more abstract structures; but for our purposes it is enough, and we are going to generalize in other directions. The above structure shows a relation between some syntactic categories, which can also be expressed by simply stating: a sentence *consists* of a subject and a predicate; and: a predicate *consists* of a verb and an object. It does not necessarily have anything to do with word order, though the order of the figure is that of the example ‘Y taught M’. What the linguist does, he *generates* the sentence. It may be done by adding substitution rules that refer to a dictionary together with a list of names and that may be expressed by dots, as follows:

![image](images/000005.png)

This picture shows that a sentence, the *linear* structure *Yājñavalkya taught Maitrey*ī, has an underlying two-dimensional *non-linear* structure \(perhaps other systems use more dimensions, but I don’t know them\). That non-linear structure, or some structures like it, have been referred to as deep structure. It has a mysterious ring about it, but teaches us that the analysis of sentences shows that there are underlying, invisible structures that have to be postulated in order to explain the sentences that are produced and that we can hear.

How do we know that the above structure is the correct one? By analysing thousands of sentences. It makes no sense, for example, to analyse as follows:

![image](images/000013.png)

One reason is that there are many sentences in which the predicate consists only of a verb which is intransitive, e.g., *Yājñavalkya sits*. They share many properties with the sentences which have transitive verbs and objects leading to the postulation of a separate category called ‘Predicate’.

Systems like these were introduced by Noam Chomsky half a century ago. They attracted large numbers of researchers, but became increasingly complex. In 1995, Chomsky replaced them by a simpler but much more abstract system called *The Minimalist Program*. Since then, developments in linguistics have become even more explosive.

Our problems are different. We are interested in infinite recursive structures. Take the sentence: ‘He said *A*”.’ I shall not analyse it into Subject \(‘He’\) and Predicate \(‘said A’\) but cut it up differently, illustrating thereby what we call *quoting*. Quoting is recursive, we can continue to do it: ‘He said, “He said *A*”.’ I can go on but let me introduce a little variation: ‘A retorted, according to B, that C had said *X*.’ It is still abstract and stilted, so ‘We might think of the Professor who claimed that Proust had written *Vanity Fair*’. That is better although Proust himself is miles ahead: ‘And so I could not help reciting to myself, when I saw them, not indeed the lines of Racine that had come into my head at the Princesses de Guermantes’s while M. de Vaugoubert stood watching young embassy secretaries greet M. de Charlus, but other lines of Racine …’ and on it goes without losing the attention of the attentive reader or syntactician.

Let me be a little more systematic and distinguish *right-recursive* and *left-recursive*. An English example of the first is: ‘Remarkable is the rapidity of the motion of the wing of the hummingbird.’ The noun phrase to which something is added is always on the right:
>
> the rapidity of the hummingbird,

> the rapidity of the wing of the hummingbird,

> the rapidity of the motion of the wing of the

> hummingbird, etc.\(?\)

We are lucky in that English possesses a similar structure which goes the other way and is therefore called *left-recursive* because the noun phrase is always on the left:
>
> the hummingbird’s rapidity

> the hummingbird’s wing’s rapidity

> the hummingbird’s wing’s motion’s rapidity, etc. \(?\)

Psychologists are interested in these recursions. I have taken the last six phrases from an article by George Miller on psycholinguistics that is almost half a century old. It illustrates the distinction Chomsky introduced between *competence* and *performance*. The rules of grammar depict a speaker’s competence. The six phrases are examples of performance. But I have put a \(?\) at the end of some of them. How far can the reader go? Asking Harvard undergraduates, Miller arrived at the conclusion that the third and sixth illustrate their limit.

The reader will now have an inkling of what mantras and Vedic rites can be like. Our next question is different: how can these different structures be learnt?

Through the interplay of empirical information and innate knowledge. Learning a language takes place for a only a small part by explicit instruction of a mother, father or teacher. It is mainly picked up by babies, from a very early age, by being immersed in a language community in which people, including playmates, visitors, salesmen, brothers, sisters, fathers, mothers, teachers or anyone or anything within hearing of the child, including the TV, uses the language. This picking up of language occurs within a few years and is similar to the way scientists learn about the world. They construe a succession of theories, each the result of earlier theories and new data. Children are quick to change their theories when they make a wrong generalization, for example, in English: from *trees*, *dogs* and *books* to \**mans* and \**womans* \(the asterisk denotes ungrammaticality\) until they notice or are told that they should say *men* and *women*.

Many ‘deep structures’ are innate. The deeper they are, the more abstract they look to us. What is not innate is the association of fragments of speech with events, occurrences or objects in the outside world. Those are picked up by the child by not only listening but by seeing and using other mental capacities such as association, generalization, combinations of various kinds and, of course, memory.

Mantras are similar in some respects. They incorporate recursive structures. They may be long and there are many of them. In Tantrism it is said that seventy million of them exist in superior worlds. But mantras are not learnt in the way language is picked up as we shall see at the end of this chapter.


